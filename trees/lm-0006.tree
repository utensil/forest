\import{lm-macros}

\tag{lm}
\tag{draft}

\note{opening thoughts}{
\p{
My recent learning has become too scattered, and I have long wished to write notes on LM, i.e. language models, so I hope focusing on this would prevent me from losing focus.
}

\p{
I've settled on the prefix \code{lm} instead of \code{llm} as I think phrases like "small LLMs" is ridiculous, and I hope LM will include *LM, such as VLM, i.e. visual language models.
}

\p{
The interest doesn't stop there, I haven't given a good read on diffuion models, and I wish to see its marrige with LMs, or at least, the perspective of diffusion models in LMs.
}

\p{
As my interest in the LM world is quite diverse, I will write the notes not as one series, but a few series, so I have reserved lm-0002 through lm-0005 for root notes for a handful of such notes. The topics that come to mind include:

\ul{
    \li{math behind LMs since ML}
    \li{various optimization methods of LMs, including GPU programming}
    \li{post-training techniques}
    \li{application of GA in LMs}
    \li{alternative architectures of LMs, that includes RWKV, stuff related to diffusion models}
}
}

\p{
Individual notes would be written as I read related papers/books, they might be reused in any of these root notes.
}

\p{I have scattered notes about LMs previously, here I list them for easier reference.

\ul{
    \li{[Transformers: from self-attention to performance optimizations](https://utensil.github.io/blog/posts/transformer/)}
    \li{[LLM Daily Picks](https://github.com/utensil/llm-playground/blob/main/daily_picks.md)}
    \li{[[uts-002B]]}
    \li{[[2025-05-02]]}
}

}

\p{
This is also an experiment to see if VLM nowadays could serve better at converting screenshots to forester math formula markups.
}

\p{
In [Transformers: from self-attention to performance optimizations](https://utensil.github.io/blog/posts/transformer/), I was very obsessed with visualizing transformer architectures, using subscript-free tensor notations ("Named Tensor Notation" \citek{chiang2021named}), but actually in math, stuff can be written out succinctly, one just needs to be able to visualize them in mind. In this seris of notes, I'll be focusing more on the actual math instead of visualization or approachable explanations, as I have grown beyond the period after reading hundreds of papers on LMs.
}

}
