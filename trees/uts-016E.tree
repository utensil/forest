\import{macros}
% clifford hopf spin tt ag math draft tech exp notes
\tag{draft}

\mdnote{some HF papers worth skimming}{
- multimodal, diffusion
    - [Scaling Diffusion Transformers Efficiently via μP](https://huggingface.co/papers/2505.15270)
        - establish μP as a principled and efficient scaling strategy for diffusion Transformers
        - with appendix on Theoretical Background of μP
    - [Neurosymbolic Diffusion Models](https://huggingface.co/papers/2505.13138)
        - the first method to integrate masked diffusion models as the neural network extractor in neurosymbolic predictors
        - with a very long appendix on math background
    - [Diffusion vs. Autoregressive Language Models: A Text Embedding Perspective](https://huggingface.co/papers/2505.15045)
        - propose adopting diffusion language models for text embeddings, motivated by their inherent bidirectional architecture and recent success in matching or surpassing LLMs especially on reasoning tasks
        - focus on [Dream 7b: Introducing dream 7b, the most powerful open diffusion large language model to date](https://hkunlp.github.io/blog/2025/dream/)
            - consistently outperforms existing diffusion language models by a large margin
            - matches or exceeds top-tier Autoregressive (AR) language models of similar size on the general, math, and coding abilities
            - demonstrates strong planning ability and inference flexibility that naturally benefits from the diffusion modeling
            - virtually all leading LLMs relying on this same sequential left-to-right architecture
            - Discrete diffusion models (DMs) have gained attention as a promising alternative for sequence generation since their introduction to the text domain, which dynamically refine the full sequence in parallel starting from a fully noised state
    - [MMaDA: Multimodal Large Diffusion Language Models](https://huggingface.co/papers/2505.15809)
    - [LaViDa: A Large Diffusion Language Model for Multimodal Understanding](https://huggingface.co/papers/2505.16839)
    - [GRIT: Teaching MLLMs to Think with Images](https://huggingface.co/papers/2505.15879)
    - [Dimple: Discrete Diffusion Multimodal Large Language Model with Parallel Decoding](https://huggingface.co/papers/2505.16990)
    - [dKV-Cache: The Cache for Diffusion Language Models](https://huggingface.co/papers/2505.15781)
    - [Understanding Generative AI Capabilities in Everyday Image Editing Tasks](https://huggingface.co/papers/2505.16181)
    - [Hunyuan-Game: Industrial-grade Intelligent Game Creation Model](https://huggingface.co/papers/2505.14135)
- efficiency
    - [Scaling Law for Quantization-Aware Training](https://huggingface.co/papers/2505.14302)
    - [Fine-tuning Quantized Neural Networks with Zeroth-order Optimization](https://huggingface.co/papers/2505.13430)
    - [A Token is Worth over 1,000 Tokens: Efficient Knowledge Distillation through Low-Rank Clone](https://huggingface.co/papers/2505.12781)
- agents, reasoning, RL
    - [NovelSeek: When Agent Becomes the Scientist -- Building Closed-Loop System from Hypothesis to Verification](https://huggingface.co/papers/2505.16938)
    - [Reinforcement Learning Finetunes Small Subnetworks in Large Language Models](https://huggingface.co/papers/2505.11711)
    - [Tool-Star: Empowering LLM-Brained Multi-Tool Reasoner via Reinforcement Learning](https://huggingface.co/papers/2505.16410)
    - [AceReason-Nemotron: Advancing Math and Code Reasoning through Reinforcement Learning](https://huggingface.co/papers/2505.16400)
    - [Training-Free Reasoning and Reflection in MLLMs](https://huggingface.co/papers/2505.16151)
    - [Date Fragments: A Hidden Bottleneck of Tokenization for Temporal Reasoning](https://huggingface.co/papers/2505.16088)
    - [RLVR-World: Training World Models with Reinforcement Learning](https://huggingface.co/papers/2505.13934)
    - [SPhyR: Spatial-Physical Reasoning Benchmark on Material Distribution](https://huggingface.co/papers/2505.16048)
    - [Risk-Averse Reinforcement Learning with Itakura-Saito Loss](https://huggingface.co/papers/2505.16925)
- safety
    - [Phare: A Safety Probe for Large Language Models](https://huggingface.co/papers/2505.11365)
    - [Audio Jailbreak: An Open Comprehensive Benchmark for Jailbreaking Large Audio-Language Models](https://huggingface.co/papers/2505.15406)
- application
    - [Steering Large Language Models for Machine Translation Personalization](https://huggingface.co/papers/2505.16612)
    - [This Time is Different: An Observability Perspective on Time Series Foundation Models](https://huggingface.co/papers/2505.14766)
    - [Prior Prompt Engineering for Reinforcement Fine-Tuning](https://huggingface.co/papers/2505.14157)
    - [Using Large Language Models for Commit Message Generation: A Preliminary Study](https://arxiv.org/abs/2401.05926)
    - [The Distracting Effect: Understanding Irrelevant Passages in RAG](https://huggingface.co/papers/2505.06914)
}
